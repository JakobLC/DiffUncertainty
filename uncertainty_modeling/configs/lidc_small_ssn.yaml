# @package _global_
defaults:
  - _self_
  - datamodule: lidc_2d_small
  - model: hrnet_ssn
  - data_augmentations: tta_lidc_2d_small

exp_name: "lidc-small-snn"
version: null
ckpt_path: null

dataset: "lidc_2d_small"
data_input_dir: "/home/jloch/Desktop/diff/luzern/values_datasets/${dataset}"
save_dir: "/home/jloch/Desktop/diff/luzern/values/saves"

seed: 123
pretrain_epochs: 5
batch_size: 16
evaluate_training_data: true

# training hyperparams
learning_rate: 0.0001
weight_decay: 0.0005

optimizer:
  _target_: torch.optim.RMSprop
  lr: ${learning_rate}
  weight_decay: ${weight_decay}
  momentum: 0.85 # 0.6 w BS 6 approximate. m_new=1-B_old/B_new*(1-m_old)=1-6/16*(1-0.6)=0.85
  # alpha: 0.9

lr_scheduler:
  _target_: torch.optim.lr_scheduler.PolynomialLR
  power: 0.9

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ${save_dir}
  name: ${exp_name}

progress_bar:
  _target_: pytorch_lightning.callbacks.TQDMProgressBar
  refresh_rate: 10

trainer:
  max_epochs: 300
  accelerator: gpu
  devices: 1
  precision: 32 # bf16-mixed
  # deterministic: true 
  # gradient_clip_val: 0.0
  # gradient_clip_algorithm: norm
  # log_every_n_steps: 50
  # check_val_every_n_epoch: 1
