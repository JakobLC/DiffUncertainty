# @package _global_
defaults:
  - _self_
  - datamodule: lidc_2d_small
  - model: hrnet_softmax_mini
  - data_augmentations: tta_lidc_2d_small

exp_name: "lidc-small-softmax-OF-mini"
version: null
ckpt_path: null

dataset: "lidc_2d_small"
data_input_dir: "/home/jloch/Desktop/diff/luzern/values_datasets/${dataset}"
save_dir: "/home/jloch/Desktop/diff/luzern/values/saves"

seed: 123
pretrain_epochs: 5
batch_size: 64
evaluate_training_data: true
evaluate_all_raters: true

# training hyperparams
learning_rate: 0.0001
weight_decay: 0.0

augment_mult: 0.0

optimizer:
  _target_: torch.optim.AdamW
  lr: ${learning_rate}
  weight_decay: ${weight_decay}

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ${save_dir}
  name: ${exp_name}
  default_hp_metric: false

progress_bar:
  _target_: pytorch_lightning.callbacks.TQDMProgressBar
  refresh_rate: 10

trainer:
  max_epochs: 500
  accelerator: gpu
  devices: 1
  precision: 32 # bf16-mixed
  # deterministic: true 
  # gradient_clip_val: 0.0
  # gradient_clip_algorithm: norm
  # log_every_n_steps: 50
  # check_val_every_n_epoch: 1

ckpt_save_freq:
  use_linear_saving: false
  use_exponential_saving: true
  only_small_ckpts: true
  track_ema_weights: true
  only_save_ema: true
  ema_decay: 0.999
  linear_freq: 10
  exponent_base: 1.3
  exponential_start: 10
  end: ${trainer.max_epochs}
  full_last_ckpt: true
  shutdown_timer: 82800 # 23 hours
  do_shutdown: false